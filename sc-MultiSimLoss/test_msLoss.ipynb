{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import hnswlib\n",
    "from modules import network,mlp\n",
    "from modules.memory_bank import StaticMemoryBank_for_MSLOSS\n",
    "from modules.multi_similarity_loss import MultiSimilarityLoss,MultiSimilarityLoss_Boost\n",
    "from utils import yaml_config_hook,save_model,data_preocess\n",
    "from evaluation import  evaluation_tools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "config = yaml_config_hook(\"config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "args = parser.parse_args([])\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "class_num = args.classnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (8569, 2000), Y Shape: (8569, 1)\n"
     ]
    }
   ],
   "source": [
    "x_ndarray,y_ndarray=data_preocess.data_process(x_path='data/filtered_Counts.npz',y_path='data/annoData.txt',args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "scDataset = TensorDataset(torch.tensor(x_ndarray, dtype=torch.float32))\n",
    "\n",
    "scDataLoader = DataLoader(scDataset, shuffle=True, batch_size=args.batch_size,drop_last=True)\n",
    "\n",
    "for features in scDataLoader:\n",
    "    print(len(features))\n",
    "    print(len(features[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticMemoryBank_for_MSLOSS_SelfEnhanced():\n",
    "\n",
    "    def __init__(self,batch_size,x,dim,nn_counts):\n",
    "        self.batch_size=batch_size\n",
    "        self.dim=dim\n",
    "        self.nn_counts=nn_counts\n",
    "        self.bank=hnswlib.Index(space='cosine',dim=dim)\n",
    "        self.bank.init_index(max_elements=8569, ef_construction=100, M=16)\n",
    "        self.bank.set_ef(100)\n",
    "        self.bank.set_num_threads(4)\n",
    "        self.bank.add_items(x)\n",
    "        self.x_data=x\n",
    " \n",
    "    def generate_data(self,sample):\n",
    "\n",
    "        labels,distances=self.bank.knn_query(sample,k=self.nn_counts)\n",
    "        pseudolabel=np.arange(labels.shape[0])\n",
    "        pseudolabel=np.repeat(pseudolabel,self.nn_counts).reshape(-1)\n",
    "        \n",
    "        print(labels[0])\n",
    "        self_index=labels[:,0]\n",
    "        labels[:,-1]=self_index\n",
    "        labels[:,-2]=self_index\n",
    "        labels[:,-3]=self_index\n",
    "        print(self_index.shape)\n",
    "        print(labels.shape)\n",
    "        print(labels[0])\n",
    "        labels=labels.reshape(-1)\n",
    "\n",
    "        data=self.x_data[labels]\n",
    "\n",
    "        return data,pseudolabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8064 7282 7868 3099 7901 7292 7961 7291 7894 7286]\n",
      "(512,)\n",
      "(512, 10)\n",
      "[8064 7282 7868 3099 7901 7292 7961 8064 8064 8064]\n",
      "(5120,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "memoryBank=StaticMemoryBank_for_MSLOSS_SelfEnhanced(batch_size=args.batch_size,x=x_ndarray,dim=2000,nn_counts=args.NN_COUNT)\n",
    "for features, in scDataLoader:\n",
    "    feature,label=memoryBank.generate_data(features.numpy())\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpp=mlp.MLP()\n",
    "model=network.Network(mlpp,feature_dim=args.feature_dim)\n",
    "model.to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "memory_bank=StaticMemoryBank_for_MSLOSS(args.batch_size,x_ndarray,args.num_genes,args.NN_COUNT)\n",
    "ms_loss_boost=MultiSimilarityLoss_Boost(args=args)\n",
    "ms_loss=MultiSimilarityLoss(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2560, 2560])\n",
      "torch.Size([2560, 2560])\n",
      "torch.Size([25600])\n",
      "torch.Size([6528000])\n",
      "tensor([True, True, True,  ..., True, True, True], device='cuda:0')\n",
      "tensor(0.9999, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor([0.9000, 0.8988, 0.8992,  ..., 0.8989, 0.8993, 0.9000], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([True, True, True,  ..., True, True, True], device='cuda:0')\n",
      "torch.Size([25600])\n",
      "torch.Size([6528000])\n",
      "Step [0/33]\t,  MSLoss_BoostL5.466931343078613\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_epoch=0\n",
    "for step,data in enumerate(scDataLoader):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    data,pseudolabel=memory_bank.generate_data(data[0].numpy())\n",
    "    data=torch.tensor(data,dtype=torch.float32).to('cuda')\n",
    "    pseudolabel=torch.tensor(pseudolabel,dtype=torch.long).to('cuda')\n",
    "    embedding=model(data)\n",
    "#     loss=ms_loss(embedding,pseudolabel)\n",
    "    loss_1=ms_loss_boost(embedding,pseudolabel)\n",
    "    loss_1.backward()\n",
    "    optimizer.step()\n",
    "    loss_epoch+=loss_1.item()\n",
    "    if step % 2 == 0:\n",
    "            print(f\"Step [{step}/{len(scDataLoader)}]\\t,  MSLoss_BoostL{loss_1.item()}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c12a03cda4ff7f748cca20ded5f2f563553d26b87c906453c28c9baf654f05d7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
