{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import os\n",
    "import anndata\n",
    "import math\n",
    "import hnswlib\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import network,mlp,contrastive_loss\n",
    "from utils import yaml_config_hook,save_model\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "config = yaml_config_hook(\"config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "args = parser.parse_args([])\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "# torch.cuda.manual_seed_all(args.seed)\n",
    "# torch.cuda.manual_seed(args.seed)\n",
    "# np.random.seed(args.seed)\n",
    "class_num = args.classnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tom-G\\.conda\\envs\\torchenv\\lib\\site-packages\\anndata\\_core\\anndata.py:107: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if index_name in anno:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8569, 2000) (8569, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>41</th>\n",
       "      <th>45</th>\n",
       "      <th>62</th>\n",
       "      <th>68</th>\n",
       "      <th>106</th>\n",
       "      <th>133</th>\n",
       "      <th>147</th>\n",
       "      <th>...</th>\n",
       "      <th>19763</th>\n",
       "      <th>19786</th>\n",
       "      <th>19808</th>\n",
       "      <th>19854</th>\n",
       "      <th>19883</th>\n",
       "      <th>20021</th>\n",
       "      <th>20073</th>\n",
       "      <th>20109</th>\n",
       "      <th>20121</th>\n",
       "      <th>20124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.302199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.36896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637877</td>\n",
       "      <td>0.368960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.351171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888292</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.711146</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509045</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509045</td>\n",
       "      <td>0.509045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     2        10   13   41   45        62       68  106  133  147  ...  19763  \\\n",
       "0  0.0  1.302199  0.0  0.0  0.0  0.000000  0.36896  0.0  0.0  0.0  ...    0.0   \n",
       "1  0.0  1.351171  0.0  0.0  0.0  0.000000  0.00000  0.0  0.0  0.0  ...    0.0   \n",
       "2  0.0  0.000000  0.0  0.0  0.0  0.000000  0.00000  0.0  0.0  0.0  ...    0.0   \n",
       "3  0.0  0.000000  0.0  0.0  0.0  0.711146  0.00000  0.0  0.0  0.0  ...    0.0   \n",
       "4  0.0  0.000000  0.0  0.0  0.0  0.509045  0.00000  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "      19786  19808  19854    19883  20021  20073  20109     20121     20124  \n",
       "0  0.000000    0.0    0.0  0.00000    0.0    0.0    0.0  0.637877  0.368960  \n",
       "1  0.000000    0.0    0.0  0.00000    0.0    0.0    0.0  0.888292  0.000000  \n",
       "2  0.000000    0.0    0.0  0.00000    0.0    0.0    0.0  0.000000  0.000000  \n",
       "3  0.417500    0.0    0.0  0.93785    0.0    0.0    0.0  0.937850  0.000000  \n",
       "4  0.509045    0.0    0.0  0.00000    0.0    0.0    0.0  0.509045  0.509045  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "sparse_X = scipy.sparse.load_npz('data/filtered_Counts.npz')\n",
    "annoData = pd.read_table('data/annoData.txt')\n",
    "y = annoData[\"cellIden\"].to_numpy()\n",
    "high_var_gene = args.num_genes\n",
    "# normlization and feature selection\n",
    "adataSC = anndata.AnnData(X=sparse_X, obs=np.arange(sparse_X.shape[0]), var=np.arange(sparse_X.shape[1]))\n",
    "sc.pp.filter_genes(adataSC, min_cells=10)\n",
    "adataSC.raw = adataSC\n",
    "sc.pp.highly_variable_genes(adataSC, n_top_genes=high_var_gene, flavor='seurat_v3')\n",
    "sc.pp.normalize_total(adataSC, target_sum=1e4)\n",
    "sc.pp.log1p(adataSC)\n",
    "\n",
    "adataNorm = adataSC[:, adataSC.var.highly_variable]\n",
    "dataframe = adataNorm.to_df()\n",
    "x_ndarray = dataframe.values.squeeze()\n",
    "y_ndarray = np.expand_dims(y, axis=1)\n",
    "print(x_ndarray.shape,y_ndarray.shape)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1024\n",
      "1024\n",
      "2000\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,random_split,TensorDataset\n",
    "scDataset = TensorDataset(torch.tensor(x_ndarray, dtype=torch.float32),\n",
    "                              torch.tensor(y_ndarray, dtype=torch.float32))\n",
    "\n",
    "scDataLoader = DataLoader(scDataset, shuffle=True, batch_size=args.batch_size,drop_last=True)\n",
    "\n",
    "for features, labels in scDataLoader:\n",
    "    print(len(features[-1]))\n",
    "    print(len(features))\n",
    "    print(len(labels))\n",
    "    break\n",
    "\n",
    "scGenDataLoader = DataLoader(scDataset, shuffle=False, batch_size=args.batch_size,drop_last=True)\n",
    "\n",
    "for features, labels in scDataLoader:\n",
    "    print(len(features[-1]))\n",
    "    print(len(features))\n",
    "    print(len(labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.  958.  284. 2326. 2525.  601. 1077.  252.   18.  255.   55.   25.\n",
      "  173.   13.    7.]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "y_count=np.zeros(args.classnum+1)\n",
    "for i in range (0,args.classnum):\n",
    "    y_count[i+1]=y_ndarray[y_ndarray==(i+1)].size\n",
    "\n",
    "plt.bar(x=np.arange(0,len(y_count)),height=y_count)\n",
    "plt.show()\n",
    "print(y_count)\n",
    "rare_y_index=[8,10,11,13,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryBank_Rare():\n",
    "\n",
    "    # 初始化，传入参数\n",
    "    def __init__(self,batch_size,full_data,topK=10):\n",
    "        self.topK=topK\n",
    "        self.batch_size=batch_size\n",
    "        self.bank=None\n",
    "        self.full_data=full_data\n",
    "\n",
    "    # 根据在updateBank中更新的hnsw对象以及输入的数据data（这里可以是embedding）提取TopK个近邻的数据\n",
    "    # 返回的结果是一个形状为[TopK,batch_size,num_genes]的数组，从第一个维度来看，\n",
    "    # 每个[batch_size,num_genes]的子数组都是根据输入的数据data寻找的一个近邻，一共TopK个\n",
    "    def generateContrast(self,data,label):\n",
    "        if self.bank is not None:\n",
    "            contrasts=np.empty((self.topK,args.batch_size,args.num_genes))\n",
    "            (x_data,y_data)=self.full_data\n",
    "            rare_index=np.where(y_data in )\n",
    "\n",
    "            labels,distances=self.bank.knn_query(data,k=self.topK)\n",
    "            \n",
    "            # print(labels)\n",
    "\n",
    "            for step,label in enumerate(labels):\n",
    "                contrasts[:,step]=self.full_data[label.tolist()]\n",
    "            return contrasts\n",
    "        else:\n",
    "            print('Memory Bank has not been initialized......')\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    # 根据输入的embedding更新hnsw对象\n",
    "    def updateBank(self,embedding):\n",
    "        num_elements=len(embedding)\n",
    "        dim=embedding.shape[1]\n",
    "        self.bank=hnswlib.Index(space='cosine',dim=dim)\n",
    "        self.bank.init_index(max_elements=num_elements, ef_construction=100, M=16)\n",
    "        self.bank.set_ef(100)\n",
    "        self.bank.set_num_threads(4)\n",
    "        self.bank.add_items(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "mlp = mlp.MLP(num_genes=args.num_genes)\n",
    "model = network.Network(mlp, args.feature_dim, args.classnum)\n",
    "model = model.to('cuda')\n",
    "# optimizer / loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_bank=MemoryBank_Rare(args.batch_size,full_data=zip(x_ndarray,y_ndarray),topK=10)\n",
    "memory_bank.updateBank(x_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'zip' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\GitHub\\scCC\\rare_modeify.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/scCC/rare_modeify.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m features,labels \u001b[39min\u001b[39;00m scDataLoader:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/scCC/rare_modeify.ipynb#ch0000008?line=1'>2</a>\u001b[0m     contrasts\u001b[39m=\u001b[39mmemory_bank\u001b[39m.\u001b[39;49mgenerateContrast(data\u001b[39m=\u001b[39;49mfeatures\u001b[39m.\u001b[39;49mnumpy(),label\u001b[39m=\u001b[39;49mlabels\u001b[39m.\u001b[39;49mnumpy())\n",
      "\u001b[1;32md:\\Documents\\GitHub\\scCC\\rare_modeify.ipynb Cell 5'\u001b[0m in \u001b[0;36mMemoryBank_Rare.generateContrast\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/scCC/rare_modeify.ipynb#ch0000004?line=17'>18</a>\u001b[0m     \u001b[39m# print(labels)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/scCC/rare_modeify.ipynb#ch0000004?line=19'>20</a>\u001b[0m     \u001b[39mfor\u001b[39;00m step,label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(labels):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/scCC/rare_modeify.ipynb#ch0000004?line=20'>21</a>\u001b[0m         contrasts[:,step]\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_data[label\u001b[39m.\u001b[39;49mtolist()]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/scCC/rare_modeify.ipynb#ch0000004?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m contrasts\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/scCC/rare_modeify.ipynb#ch0000004?line=22'>23</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'zip' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for features,labels in scDataLoader:\n",
    "    contrasts=memory_bank.generateContrast(data=features.numpy(),label=labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_epoch=0\n",
    "for step,(data,label) in enumerate(scDataLoader):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # if epoch<20:\n",
    "    embedding_data=data.numpy().copy()\n",
    "    data=data.to('cuda')\n",
    "    label=label.numpy().copy()\n",
    "    # else:\n",
    "    #     data=data.to('cuda')\n",
    "    #     embedding_data=model.forward_embedding(data).cpu().detach().numpy()    \n",
    "    contrast_samples=memory_bank.generateContrast(embedding_data)\n",
    "    iter_times=contrast_samples.shape[0]\n",
    "    for sample in contrast_samples:\n",
    "        # print(f'sample shape:\\n{sample.shape}')\n",
    "        # print(f'data shape:\\n{data.shape}')\n",
    "        x_i=data.clone()\n",
    "        x_j=torch.tensor(sample,dtype=torch.float32).to('cuda')\n",
    "\n",
    "        z_i,z_j,c_i,c_j=model(x_i,x_j)\n",
    "        loss_instance=instance_loss(z_i,z_j)\n",
    "        loss_cluster=cluster_loss(c_i,c_j)\n",
    "        loss = loss_instance + loss_cluster\n",
    "        # print(f'------ loss:\\n{loss}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch+=loss.item()\n",
    "    if step % 2 == 0:\n",
    "            print(f\"Step [{step}/{len(scDataLoader)}]\\t loss_instance: {loss_instance.item()}\\t loss_cluster: {loss_cluster.item()}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c12a03cda4ff7f748cca20ded5f2f563553d26b87c906453c28c9baf654f05d7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
