{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import os\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Environment\\Conda\\envs\\torchenv\\lib\\site-packages\\anndata\\_core\\anndata.py:107: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if index_name in anno:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8569,)\n",
      "(8569, 6000) (8569,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "          1    2    4       7        10   13   26   31        32   33  ...  \\\n0  1.024218  0.0  0.0  0.0000  1.302199  0.0  0.0  0.0  0.637877  0.0  ...   \n1  0.000000  0.0  0.0  0.0000  1.351171  0.0  0.0  0.0  0.000000  0.0  ...   \n2  0.000000  0.0  0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  ...   \n3  0.000000  0.0  0.0  0.4175  0.000000  0.0  0.0  0.0  0.000000  0.0  ...   \n4  0.000000  0.0  0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  ...   \n\n    20104  20105    20108  20109   20115  20118     20121   20122     20123  \\\n0  0.0000    0.0  0.36896    0.0  0.0000    0.0  0.637877  0.0000  0.000000   \n1  0.0000    0.0  0.00000    0.0  0.0000    0.0  0.888292  0.0000  0.305824   \n2  0.0000    0.0  0.00000    0.0  0.0000    0.0  0.000000  0.0000  0.000000   \n3  0.4175    0.0  0.00000    0.0  0.4175    0.0  0.937850  0.4175  0.000000   \n4  0.0000    0.0  0.00000    0.0  0.0000    0.0  0.509045  0.0000  0.000000   \n\n      20124  \n0  0.368960  \n1  0.000000  \n2  0.000000  \n3  0.000000  \n4  0.509045  \n\n[5 rows x 6000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>4</th>\n      <th>7</th>\n      <th>10</th>\n      <th>13</th>\n      <th>26</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>...</th>\n      <th>20104</th>\n      <th>20105</th>\n      <th>20108</th>\n      <th>20109</th>\n      <th>20115</th>\n      <th>20118</th>\n      <th>20121</th>\n      <th>20122</th>\n      <th>20123</th>\n      <th>20124</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.024218</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.302199</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.637877</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.36896</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.637877</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.368960</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>1.351171</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.888292</td>\n      <td>0.0000</td>\n      <td>0.305824</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.4175</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.4175</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.4175</td>\n      <td>0.0</td>\n      <td>0.937850</td>\n      <td>0.4175</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.509045</td>\n      <td>0.0000</td>\n      <td>0.000000</td>\n      <td>0.509045</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 6000 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "sparse_X = scipy.sparse.load_npz('data/filtered_Counts.npz')\n",
    "annoData = pd.read_table('data/annoData.txt')\n",
    "y = annoData[\"cellIden\"].to_numpy()\n",
    "high_var_gene = 6000\n",
    "# normlization and feature selection\n",
    "adataSC = anndata.AnnData(X=sparse_X, obs=np.arange(sparse_X.shape[0]), var=np.arange(sparse_X.shape[1]))\n",
    "sc.pp.filter_genes(adataSC, min_cells=10)\n",
    "adataSC.raw = adataSC\n",
    "sc.pp.highly_variable_genes(adataSC, n_top_genes=high_var_gene, flavor='seurat_v3')\n",
    "sc.pp.normalize_total(adataSC, target_sum=1e4)\n",
    "sc.pp.log1p(adataSC)\n",
    "\n",
    "adataNorm = adataSC[:, adataSC.var.highly_variable]\n",
    "dataframe = adataNorm.to_df()\n",
    "x_ndarray = dataframe.values.squeeze()\n",
    "y_ndarray = y.reshape(8569,)\n",
    "print(y_ndarray.shape)\n",
    "print(x_ndarray.shape,y_ndarray.shape)\n",
    "dataframe.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from modules import network\n",
    "from utils import yaml_config_hook,save_model\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "config = yaml_config_hook(\"config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "args = parser.parse_args([])\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "class_num = len(np.unique(y_ndarray))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6855 1714\n",
      "6000\n",
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,random_split,TensorDataset\n",
    "\n",
    "# y_label=nn.functional.one_hot(torch.tensor(y_ndarray-1,dtype=torch.int64),num_classes=class_num)\n",
    "scDataset = TensorDataset(torch.tensor(x_ndarray, dtype=torch.float32),\n",
    "                              torch.tensor(y_ndarray-1, dtype=torch.int64))\n",
    "\n",
    "scTrainLength = int(len(scDataset) * 0.8)\n",
    "scValidLength = len(scDataset) - scTrainLength\n",
    "scTrain, scValid = random_split(scDataset, [scTrainLength, scValidLength])\n",
    "print(len(scTrain),len(scValid))\n",
    "scTrainDataLoader = DataLoader(scTrain, shuffle=True, batch_size=args.batch_size,drop_last=True)\n",
    "scValidDataLoader = DataLoader(scValid, shuffle=True, batch_size=args.batch_size,drop_last=True)\n",
    "\n",
    "for features, labels in scTrainDataLoader:\n",
    "    print(len(features[-1]))\n",
    "    print(len(features))\n",
    "    print(len(labels))\n",
    "    break\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1024]       6,145,024\n",
      "              ReLU-2                 [-1, 1024]               0\n",
      "           Dropout-3                 [-1, 1024]               0\n",
      "            Linear-4                  [-1, 512]         524,800\n",
      "              ReLU-5                  [-1, 512]               0\n",
      "           Dropout-6                  [-1, 512]               0\n",
      "            Linear-7                  [-1, 256]         131,328\n",
      "              ReLU-8                  [-1, 256]               0\n",
      "           Dropout-9                  [-1, 256]               0\n",
      "           Linear-10                  [-1, 128]          32,896\n",
      "             ReLU-11                  [-1, 128]               0\n",
      "          Dropout-12                  [-1, 128]               0\n",
      "           Linear-13                   [-1, 64]           8,256\n",
      "             ReLU-14                   [-1, 64]               0\n",
      "          Dropout-15                   [-1, 64]               0\n",
      "           Linear-16                   [-1, 14]             910\n",
      "================================================================\n",
      "Total params: 6,843,214\n",
      "Trainable params: 6,843,214\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.022888\n",
      "Forward/backward pass size (MB): 0.045517\n",
      "Params size (MB): 26.104790\n",
      "Estimated Total Size (MB): 26.173195\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from modules import mlp\n",
    "network=mlp.ValidMLP(num_genes=args.num_genes)\n",
    "from torchkeras import summary\n",
    "summary(network,input_shape=(6000,))\n",
    "network=network.to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "loss_device=torch.device('cuda')\n",
    "loss_func = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(params=network.parameters(),lr = 0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def train():\n",
    "    global batch_idx\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, data in enumerate(scTrainDataLoader, 1):\n",
    "        inputs, target = data\n",
    "        inputs=inputs.to('cuda')\n",
    "        target=target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = network(inputs)\n",
    "        loss = loss_func(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx%10==0:\n",
    "             print(\"[step = %d] loss: %.3f \" % (batch_idx, running_loss / batch_idx))\n",
    "    return running_loss / batch_idx\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in scValid:\n",
    "            inputs, labels = data\n",
    "            inputs=inputs.to('cuda')\n",
    "            labels=labels.to('cuda')\n",
    "            outputs = network(inputs)\n",
    "            outputs=outputs.cpu().numpy()\n",
    "            predicted = np.argmax(outputs.data)\n",
    "            total+=1\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy on test set: %d %%' % (100 * correct / total))\n",
    "    return correct/total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[step = 10] loss: 2.618 \n",
      "[step = 20] loss: 2.610 \n",
      "Accuracy on test set: 26 %\n",
      "1\n",
      "[step = 10] loss: 2.578 \n",
      "[step = 20] loss: 2.570 \n",
      "Accuracy on test set: 26 %\n",
      "2\n",
      "[step = 10] loss: 2.535 \n",
      "[step = 20] loss: 2.530 \n",
      "Accuracy on test set: 26 %\n",
      "3\n",
      "[step = 10] loss: 2.502 \n",
      "[step = 20] loss: 2.494 \n",
      "Accuracy on test set: 26 %\n",
      "4\n",
      "[step = 10] loss: 2.462 \n",
      "[step = 20] loss: 2.461 \n",
      "Accuracy on test set: 26 %\n",
      "5\n",
      "[step = 10] loss: 2.433 \n",
      "[step = 20] loss: 2.426 \n",
      "Accuracy on test set: 28 %\n",
      "6\n",
      "[step = 10] loss: 2.394 \n",
      "[step = 20] loss: 2.390 \n",
      "Accuracy on test set: 28 %\n",
      "7\n",
      "[step = 10] loss: 2.364 \n",
      "[step = 20] loss: 2.355 \n",
      "Accuracy on test set: 31 %\n",
      "8\n",
      "[step = 10] loss: 2.326 \n",
      "[step = 20] loss: 2.319 \n",
      "Accuracy on test set: 32 %\n",
      "9\n",
      "[step = 10] loss: 2.277 \n",
      "[step = 20] loss: 2.279 \n",
      "Accuracy on test set: 33 %\n",
      "10\n",
      "[step = 10] loss: 2.231 \n",
      "[step = 20] loss: 2.234 \n",
      "Accuracy on test set: 31 %\n",
      "11\n",
      "[step = 10] loss: 2.196 \n",
      "[step = 20] loss: 2.186 \n",
      "Accuracy on test set: 32 %\n",
      "12\n",
      "[step = 10] loss: 2.138 \n",
      "[step = 20] loss: 2.129 \n",
      "Accuracy on test set: 31 %\n",
      "13\n",
      "[step = 10] loss: 2.050 \n",
      "[step = 20] loss: 2.040 \n",
      "Accuracy on test set: 31 %\n",
      "14\n",
      "[step = 10] loss: 1.987 \n",
      "[step = 20] loss: 1.985 \n",
      "Accuracy on test set: 30 %\n",
      "15\n",
      "[step = 10] loss: 1.918 \n",
      "[step = 20] loss: 1.921 \n",
      "Accuracy on test set: 32 %\n",
      "16\n",
      "[step = 10] loss: 1.878 \n",
      "[step = 20] loss: 1.863 \n",
      "Accuracy on test set: 32 %\n",
      "17\n",
      "[step = 10] loss: 1.835 \n",
      "[step = 20] loss: 1.801 \n",
      "Accuracy on test set: 32 %\n",
      "18\n",
      "[step = 10] loss: 1.758 \n",
      "[step = 20] loss: 1.758 \n",
      "Accuracy on test set: 32 %\n",
      "19\n",
      "[step = 10] loss: 1.726 \n",
      "[step = 20] loss: 1.735 \n",
      "Accuracy on test set: 32 %\n",
      "20\n",
      "[step = 10] loss: 1.702 \n",
      "[step = 20] loss: 1.688 \n",
      "Accuracy on test set: 34 %\n",
      "21\n",
      "[step = 10] loss: 1.646 \n",
      "[step = 20] loss: 1.660 \n",
      "Accuracy on test set: 34 %\n",
      "22\n",
      "[step = 10] loss: 1.634 \n",
      "[step = 20] loss: 1.638 \n",
      "Accuracy on test set: 34 %\n",
      "23\n",
      "[step = 10] loss: 1.586 \n",
      "[step = 20] loss: 1.598 \n",
      "Accuracy on test set: 37 %\n",
      "24\n",
      "[step = 10] loss: 1.591 \n",
      "[step = 20] loss: 1.561 \n",
      "Accuracy on test set: 39 %\n",
      "25\n",
      "[step = 10] loss: 1.529 \n",
      "[step = 20] loss: 1.521 \n",
      "Accuracy on test set: 43 %\n",
      "26\n",
      "[step = 10] loss: 1.478 \n",
      "[step = 20] loss: 1.469 \n",
      "Accuracy on test set: 48 %\n",
      "27\n",
      "[step = 10] loss: 1.413 \n",
      "[step = 20] loss: 1.391 \n",
      "Accuracy on test set: 52 %\n",
      "28\n",
      "[step = 10] loss: 1.344 \n",
      "[step = 20] loss: 1.337 \n",
      "Accuracy on test set: 56 %\n",
      "29\n",
      "[step = 10] loss: 1.250 \n",
      "[step = 20] loss: 1.246 \n",
      "Accuracy on test set: 59 %\n",
      "30\n",
      "[step = 10] loss: 1.191 \n",
      "[step = 20] loss: 1.182 \n",
      "Accuracy on test set: 62 %\n",
      "31\n",
      "[step = 10] loss: 1.139 \n",
      "[step = 20] loss: 1.118 \n",
      "Accuracy on test set: 66 %\n",
      "32\n",
      "[step = 10] loss: 1.064 \n",
      "[step = 20] loss: 1.066 \n",
      "Accuracy on test set: 68 %\n",
      "33\n",
      "[step = 10] loss: 1.048 \n",
      "[step = 20] loss: 1.031 \n",
      "Accuracy on test set: 68 %\n",
      "34\n",
      "[step = 10] loss: 1.012 \n",
      "[step = 20] loss: 0.986 \n",
      "Accuracy on test set: 69 %\n",
      "35\n",
      "[step = 10] loss: 0.918 \n",
      "[step = 20] loss: 0.920 \n",
      "Accuracy on test set: 69 %\n",
      "36\n",
      "[step = 10] loss: 0.887 \n",
      "[step = 20] loss: 0.875 \n",
      "Accuracy on test set: 70 %\n",
      "37\n",
      "[step = 10] loss: 0.850 \n",
      "[step = 20] loss: 0.848 \n",
      "Accuracy on test set: 72 %\n",
      "38\n",
      "[step = 10] loss: 0.831 \n",
      "[step = 20] loss: 0.815 \n",
      "Accuracy on test set: 74 %\n",
      "39\n",
      "[step = 10] loss: 0.801 \n",
      "[step = 20] loss: 0.783 \n",
      "Accuracy on test set: 75 %\n",
      "40\n",
      "[step = 10] loss: 0.763 \n",
      "[step = 20] loss: 0.754 \n",
      "Accuracy on test set: 76 %\n",
      "41\n",
      "[step = 10] loss: 0.705 \n",
      "[step = 20] loss: 0.720 \n",
      "Accuracy on test set: 78 %\n",
      "42\n",
      "[step = 10] loss: 0.674 \n",
      "[step = 20] loss: 0.688 \n",
      "Accuracy on test set: 79 %\n",
      "43\n",
      "[step = 10] loss: 0.669 \n",
      "[step = 20] loss: 0.665 \n",
      "Accuracy on test set: 79 %\n",
      "44\n",
      "[step = 10] loss: 0.648 \n",
      "[step = 20] loss: 0.642 \n",
      "Accuracy on test set: 80 %\n",
      "45\n",
      "[step = 10] loss: 0.623 \n",
      "[step = 20] loss: 0.621 \n",
      "Accuracy on test set: 81 %\n",
      "46\n",
      "[step = 10] loss: 0.571 \n",
      "[step = 20] loss: 0.587 \n",
      "Accuracy on test set: 81 %\n",
      "47\n",
      "[step = 10] loss: 0.579 \n",
      "[step = 20] loss: 0.576 \n",
      "Accuracy on test set: 81 %\n",
      "48\n",
      "[step = 10] loss: 0.545 \n",
      "[step = 20] loss: 0.553 \n",
      "Accuracy on test set: 82 %\n",
      "49\n",
      "[step = 10] loss: 0.544 \n",
      "[step = 20] loss: 0.542 \n",
      "Accuracy on test set: 83 %\n",
      "50\n",
      "[step = 10] loss: 0.518 \n",
      "[step = 20] loss: 0.525 \n",
      "Accuracy on test set: 82 %\n",
      "51\n",
      "[step = 10] loss: 0.526 \n",
      "[step = 20] loss: 0.527 \n",
      "Accuracy on test set: 83 %\n",
      "52\n",
      "[step = 10] loss: 0.531 \n",
      "[step = 20] loss: 0.490 \n",
      "Accuracy on test set: 83 %\n",
      "53\n",
      "[step = 10] loss: 0.510 \n",
      "[step = 20] loss: 0.489 \n",
      "Accuracy on test set: 83 %\n",
      "54\n",
      "[step = 10] loss: 0.500 \n",
      "[step = 20] loss: 0.478 \n",
      "Accuracy on test set: 84 %\n",
      "55\n",
      "[step = 10] loss: 0.486 \n",
      "[step = 20] loss: 0.469 \n",
      "Accuracy on test set: 84 %\n",
      "56\n",
      "[step = 10] loss: 0.450 \n",
      "[step = 20] loss: 0.449 \n",
      "Accuracy on test set: 84 %\n",
      "57\n",
      "[step = 10] loss: 0.478 \n",
      "[step = 20] loss: 0.450 \n",
      "Accuracy on test set: 83 %\n",
      "58\n",
      "[step = 10] loss: 0.436 \n",
      "[step = 20] loss: 0.426 \n",
      "Accuracy on test set: 85 %\n",
      "59\n",
      "[step = 10] loss: 0.420 \n",
      "[step = 20] loss: 0.425 \n",
      "Accuracy on test set: 85 %\n",
      "60\n",
      "[step = 10] loss: 0.425 \n",
      "[step = 20] loss: 0.417 \n",
      "Accuracy on test set: 85 %\n",
      "61\n",
      "[step = 10] loss: 0.395 \n",
      "[step = 20] loss: 0.405 \n",
      "Accuracy on test set: 85 %\n",
      "62\n",
      "[step = 10] loss: 0.409 \n",
      "[step = 20] loss: 0.391 \n",
      "Accuracy on test set: 84 %\n",
      "63\n",
      "[step = 10] loss: 0.374 \n",
      "[step = 20] loss: 0.379 \n",
      "Accuracy on test set: 85 %\n",
      "64\n",
      "[step = 10] loss: 0.382 \n",
      "[step = 20] loss: 0.375 \n",
      "Accuracy on test set: 86 %\n",
      "65\n",
      "[step = 10] loss: 0.361 \n",
      "[step = 20] loss: 0.362 \n",
      "Accuracy on test set: 86 %\n",
      "66\n",
      "[step = 10] loss: 0.374 \n",
      "[step = 20] loss: 0.365 \n",
      "Accuracy on test set: 86 %\n",
      "67\n",
      "[step = 10] loss: 0.355 \n",
      "[step = 20] loss: 0.348 \n",
      "Accuracy on test set: 87 %\n",
      "68\n",
      "[step = 10] loss: 0.332 \n",
      "[step = 20] loss: 0.335 \n",
      "Accuracy on test set: 87 %\n",
      "69\n",
      "[step = 10] loss: 0.328 \n",
      "[step = 20] loss: 0.321 \n",
      "Accuracy on test set: 87 %\n",
      "70\n",
      "[step = 10] loss: 0.322 \n",
      "[step = 20] loss: 0.312 \n",
      "Accuracy on test set: 87 %\n",
      "71\n",
      "[step = 10] loss: 0.323 \n",
      "[step = 20] loss: 0.318 \n",
      "Accuracy on test set: 88 %\n",
      "72\n",
      "[step = 10] loss: 0.305 \n",
      "[step = 20] loss: 0.308 \n",
      "Accuracy on test set: 89 %\n",
      "73\n",
      "[step = 10] loss: 0.306 \n",
      "[step = 20] loss: 0.298 \n",
      "Accuracy on test set: 89 %\n",
      "74\n",
      "[step = 10] loss: 0.284 \n",
      "[step = 20] loss: 0.297 \n",
      "Accuracy on test set: 88 %\n",
      "75\n",
      "[step = 10] loss: 0.292 \n",
      "[step = 20] loss: 0.283 \n",
      "Accuracy on test set: 89 %\n",
      "76\n",
      "[step = 10] loss: 0.294 \n",
      "[step = 20] loss: 0.279 \n",
      "Accuracy on test set: 88 %\n",
      "77\n",
      "[step = 10] loss: 0.269 \n",
      "[step = 20] loss: 0.261 \n",
      "Accuracy on test set: 89 %\n",
      "78\n",
      "[step = 10] loss: 0.266 \n",
      "[step = 20] loss: 0.256 \n",
      "Accuracy on test set: 88 %\n",
      "79\n",
      "[step = 10] loss: 0.250 \n",
      "[step = 20] loss: 0.251 \n",
      "Accuracy on test set: 89 %\n",
      "80\n",
      "[step = 10] loss: 0.267 \n",
      "[step = 20] loss: 0.255 \n",
      "Accuracy on test set: 90 %\n",
      "81\n",
      "[step = 10] loss: 0.248 \n",
      "[step = 20] loss: 0.255 \n",
      "Accuracy on test set: 89 %\n",
      "82\n",
      "[step = 10] loss: 0.230 \n",
      "[step = 20] loss: 0.242 \n",
      "Accuracy on test set: 90 %\n",
      "83\n",
      "[step = 10] loss: 0.255 \n",
      "[step = 20] loss: 0.247 \n",
      "Accuracy on test set: 90 %\n",
      "84\n",
      "[step = 10] loss: 0.235 \n",
      "[step = 20] loss: 0.230 \n",
      "Accuracy on test set: 90 %\n",
      "85\n",
      "[step = 10] loss: 0.234 \n",
      "[step = 20] loss: 0.238 \n",
      "Accuracy on test set: 90 %\n",
      "86\n",
      "[step = 10] loss: 0.223 \n",
      "[step = 20] loss: 0.220 \n",
      "Accuracy on test set: 90 %\n",
      "87\n",
      "[step = 10] loss: 0.215 \n",
      "[step = 20] loss: 0.226 \n",
      "Accuracy on test set: 91 %\n",
      "88\n",
      "[step = 10] loss: 0.230 \n",
      "[step = 20] loss: 0.221 \n",
      "Accuracy on test set: 90 %\n",
      "89\n",
      "[step = 10] loss: 0.222 \n",
      "[step = 20] loss: 0.226 \n",
      "Accuracy on test set: 90 %\n",
      "90\n",
      "[step = 10] loss: 0.202 \n",
      "[step = 20] loss: 0.210 \n",
      "Accuracy on test set: 90 %\n",
      "91\n",
      "[step = 10] loss: 0.232 \n",
      "[step = 20] loss: 0.228 \n",
      "Accuracy on test set: 90 %\n",
      "92\n",
      "[step = 10] loss: 0.212 \n",
      "[step = 20] loss: 0.215 \n",
      "Accuracy on test set: 91 %\n",
      "93\n",
      "[step = 10] loss: 0.201 \n",
      "[step = 20] loss: 0.203 \n",
      "Accuracy on test set: 89 %\n",
      "94\n",
      "[step = 10] loss: 0.199 \n",
      "[step = 20] loss: 0.207 \n",
      "Accuracy on test set: 90 %\n",
      "95\n",
      "[step = 10] loss: 0.201 \n",
      "[step = 20] loss: 0.198 \n",
      "Accuracy on test set: 90 %\n",
      "96\n",
      "[step = 10] loss: 0.199 \n",
      "[step = 20] loss: 0.196 \n",
      "Accuracy on test set: 91 %\n",
      "97\n",
      "[step = 10] loss: 0.213 \n",
      "[step = 20] loss: 0.194 \n",
      "Accuracy on test set: 90 %\n",
      "98\n",
      "[step = 10] loss: 0.202 \n",
      "[step = 20] loss: 0.192 \n",
      "Accuracy on test set: 90 %\n",
      "99\n",
      "[step = 10] loss: 0.206 \n",
      "[step = 20] loss: 0.201 \n",
      "Accuracy on test set: 90 %\n"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "accuracies=[]\n",
    "for epoch in range(100):\n",
    "    print(epoch)\n",
    "    loss=train(epoch)\n",
    "    losses.append(loss)\n",
    "    acc=test()\n",
    "    accuracies.append(acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "ax[0].plot(accuracies)\n",
    "ax[0].set_title('Accuracy during Validation')\n",
    "ax[1].plot(losses)\n",
    "ax[1].set_title('Loss during Training')\n",
    "\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.suptitle('Result')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}